{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c6b9a-ea0c-4ccf-abbb-1eadc9beb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_input(shape):\n",
    "    n, c ,h, w = shape\n",
    "    inputs = []\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    inputs.append(f\"n{i}_c{j}_h{k}_w{l}\")     \n",
    "    return np.array(inputs)\n",
    "    \n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "     \n",
    "    m = (n_stride//tn_stride)\n",
    "    print(m)\n",
    "    tensor = np.zeros(n * c * h * w * m, dtype='<U11')\n",
    "    print(tensor.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    \n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    " \n",
    "    return tensor\n",
    "\n",
    "# ipt = np.arange(4*3*2*2) + 1\n",
    "shape = (4,3,2,2)\n",
    "stride = (24,4,2,1)\n",
    "\n",
    "ipt = create_input(shape)\n",
    "res = make_tensor(ipt,shape,stride)\n",
    "print(ipt.reshape(-1,12))\n",
    "print(res.reshape(-1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada8c49-9a3a-411a-9990-75ebc60ae32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcb4979e-ac20-4aae-8565-666af8ea03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      " [13 14 15 16 17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32 33 34 35 36]\n",
      " [37 38 39 40 41 42 43 44 45 46 47 48]]\n",
      "[[ 1.  2.  0.  0.  3.  4.  0.  0.  0.  0.  0.  0.]\n",
      " [ 5.  6.  0.  0.  7.  8.  0.  0.  0.  0.  0.  0.]\n",
      " [ 9. 10.  0.  0. 11. 12.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [13. 14.  0.  0. 15. 16.  0.  0.  0.  0.  0.  0.]\n",
      " [17. 18.  0.  0. 19. 20.  0.  0.  0.  0.  0.  0.]\n",
      " [21. 22.  0.  0. 23. 24.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [25. 26.  0.  0. 27. 28.  0.  0.  0.  0.  0.  0.]\n",
      " [29. 30.  0.  0. 31. 32.  0.  0.  0.  0.  0.  0.]\n",
      " [33. 34.  0.  0. 35. 36.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [37. 38.  0.  0. 39. 40.  0.  0.  0.  0.  0.  0.]\n",
      " [41. 42.  0.  0. 43. 44.  0.  0.  0.  0.  0.  0.]\n",
      " [45. 46.  0.  0. 47. 48.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_input(shape):\n",
    "    n, c ,h, w = shape\n",
    "    inputs = []\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    inputs.append(f\"n{i}_c{j}_h{k}_w{l}\")     \n",
    "    return np.array(inputs)\n",
    "    \n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "     \n",
    "    # m = (n_stride//tn_stride)\n",
    "    # print(m)\n",
    "    # tensor = np.zeros(n * c * h * w * m)\n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    print(tensor.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    " \n",
    "    return tensor\n",
    "\n",
    "ipt = np.arange(4*3*2*2) + 1\n",
    "shape = (4,3,2,2)\n",
    "stride = (48,12,4,1)\n",
    "\n",
    "# ipt = create_input(shape)\n",
    "res = make_tensor(ipt,shape,stride)\n",
    "print(ipt.reshape(-1,12))\n",
    "print(res.reshape(-1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b1da9b6-aa69-4a8b-813c-1ad7c7b39fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 0.  0.  0.]\n",
      " [19. 20. 21.]\n",
      " [22. 23. 24.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 7.  8.  9.]\n",
      " [10. 11. 12.]\n",
      " [ 0.  0.  0.]\n",
      " [25. 26. 27.]\n",
      " [28. 29. 30.]\n",
      " [ 0.  0.  0.]]\n",
      "[[13. 14. 15.]\n",
      " [16. 17. 18.]\n",
      " [ 0.  0.  0.]\n",
      " [31. 32. 33.]\n",
      " [34. 35. 36.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "     \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    " \n",
    "    return tensor\n",
    "\n",
    "shape = (2,3,2,3)\n",
    "n, c, h, w = shape\n",
    "ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "stride = (9,9,3,1)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f47c3f-3aa6-4ed5-b007-a4c5e7860338",
   "metadata": {},
   "source": [
    "### case1 64-Bytes对齐存储方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c56d12e8-4599-4b1f-a3bd-f5bdd4b3bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
      " [17. 18. 19. 20.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [61. 62. 63. 64. 65. 66. 67. 68.]\n",
      " [69. 70. 71. 72. 73. 74. 75. 76.]\n",
      " [77. 78. 79. 80.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "========================================\n",
      "========================================\n",
      "[[ 21.  22.  23.  24.  25.  26.  27.  28.]\n",
      " [ 29.  30.  31.  32.  33.  34.  35.  36.]\n",
      " [ 37.  38.  39.  40.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 81.  82.  83.  84.  85.  86.  87.  88.]\n",
      " [ 89.  90.  91.  92.  93.  94.  95.  96.]\n",
      " [ 97.  98.  99. 100.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "========================================\n",
      "========================================\n",
      "[[ 41.  42.  43.  44.  45.  46.  47.  48.]\n",
      " [ 49.  50.  51.  52.  53.  54.  55.  56.]\n",
      " [ 57.  58.  59.  60.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [101. 102. 103. 104. 105. 106. 107. 108.]\n",
      " [109. 110. 111. 112. 113. 114. 115. 116.]\n",
      " [117. 118. 119. 120.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_aligned_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = math.ceil(h*w/16) * 16\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "# define shape & create input\n",
    "shape = (2,3,4,5)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_aligned_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,8))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320e8c7-2739-4936-9640-6f34d0d9cbcf",
   "metadata": {},
   "source": [
    "#### case2 紧凑存储方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16144b9f-9c00-44f5-bdf2-68d0686006c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
      " [17. 18. 19. 20. 61. 62. 63. 64.]\n",
      " [65. 66. 67. 68. 69. 70. 71. 72.]\n",
      " [73. 74. 75. 76. 77. 78. 79. 80.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 21.  22.  23.  24.  25.  26.  27.  28.]\n",
      " [ 29.  30.  31.  32.  33.  34.  35.  36.]\n",
      " [ 37.  38.  39.  40.  81.  82.  83.  84.]\n",
      " [ 85.  86.  87.  88.  89.  90.  91.  92.]\n",
      " [ 93.  94.  95.  96.  97.  98.  99. 100.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 41.  42.  43.  44.  45.  46.  47.  48.]\n",
      " [ 49.  50.  51.  52.  53.  54.  55.  56.]\n",
      " [ 57.  58.  59.  60. 101. 102. 103. 104.]\n",
      " [105. 106. 107. 108. 109. 110. 111. 112.]\n",
      " [113. 114. 115. 116. 117. 118. 119. 120.]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_compact_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = h*w\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "# define shape & create input\n",
    "shape = (2,3,4,5)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_compact_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,8))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb8ca4-935c-4a21-8afb-373fef41518a",
   "metadata": {},
   "source": [
    "#### case3 矩阵存储方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71e36fba-234a-4976-a14d-54176240328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [41. 42. 43. 44. 45. 46. 47. 48.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [49. 50. 51. 52. 53. 54. 55. 56.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[17. 18. 19. 20. 21. 22. 23. 24.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [57. 58. 59. 60. 61. 62. 63. 64.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[25. 26. 27. 28. 29. 30. 31. 32.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [65. 66. 67. 68. 69. 70. 71. 72.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[33. 34. 35. 36. 37. 38. 39. 40.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [73. 74. 75. 76. 77. 78. 79. 80.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_aligned_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = math.ceil(h*w/16) * 16\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "def matrix_reshape(shape, w=8):\n",
    "    m,n = shape\n",
    "    N=n\n",
    "    C=math.ceil(m/w)\n",
    "    H=1\n",
    "    W=w\n",
    "    return (N,C,H,W)\n",
    "\n",
    "# define shape & create input\n",
    "matrix_shape = (40,2)\n",
    "shape = matrix_reshape(matrix_shape)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_aligned_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,8))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd333c-2707-4660-b092-507ab92cfabb",
   "metadata": {},
   "source": [
    "### case4 向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68b9b8b6-c6b5-4df0-938d-35a8c978ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[[1. 2. 3. 4. 5. 6. 7. 8.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[17. 18. 19. 20. 21. 22. 23. 24.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[25. 26. 27. 28. 29. 30. 31. 32.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[33. 34. 35. 36. 37. 38. 39. 40.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_aligned_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = math.ceil(h*w/16) * 16\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "def vector_reshape(shape, w=8):\n",
    "    m,n = shape\n",
    "    N=n\n",
    "    C=math.ceil(m/w)\n",
    "    H=1\n",
    "    W=w\n",
    "    return (N,C,H,W)\n",
    "\n",
    "# define shape & create input\n",
    "matrix_shape = (40,1)\n",
    "shape = matrix_reshape(matrix_shape)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_aligned_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,8))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa25d0d-0d71-480a-9819-bb16fabdd344",
   "metadata": {},
   "source": [
    "####  case5 行对齐存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb85cd9-7bc2-472a-9eac-683819fddd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[[ 1.  2.  3.  4.  5.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 6.  7.  8.  9. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [11. 12. 13. 14. 15.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [16. 17. 18. 19. 20.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [61. 62. 63. 64. 65.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [66. 67. 68. 69. 70.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [71. 72. 73. 74. 75.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [76. 77. 78. 79. 80.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 21.  22.  23.  24.  25.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 26.  27.  28.  29.  30.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 31.  32.  33.  34.  35.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 36.  37.  38.  39.  40.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 81.  82.  83.  84.  85.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 86.  87.  88.  89.  90.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 91.  92.  93.  94.  95.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 96.  97.  98.  99. 100.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 41.  42.  43.  44.  45.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 46.  47.  48.  49.  50.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 51.  52.  53.  54.  55.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [ 56.  57.  58.  59.  60.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [101. 102. 103. 104. 105.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [106. 107. 108. 109. 110.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [111. 112. 113. 114. 115.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [116. 117. 118. 119. 120.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_aligned_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = math.ceil(w/16)*16\n",
    "    C_stride = H_stride * h\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "# define shape & create input\n",
    "shape = (2,3,4,5)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_aligned_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,8))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b4348-a681-4cc4-a552-bbcb71ce785c",
   "metadata": {},
   "source": [
    "### case6 64IC/32IC 存储 (FP32 1IC)\n",
    "\n",
    "这个没太懂\n",
    "\n",
    "首先是FP32遵循1IC的方式进行排列\n",
    "\n",
    "先将w维数据全放上，再放h维的数据，之后将所有n维的全放上，最后再将c维数据放上（由于有64个NPU，c维按step=64递增）\r\n",
    "事实上，这其实就是将kernel的shape当作(1,oc,ic,kh*kw)然后按照正常tensor的compact方式来排列的，因此为了方便，在bm1684x_coeff_arrange.cpp:ConvWeightArr函数中\n",
    "\n",
    "ref:https://wiki.sophgo.com/pages/viewpage.action?pageId=52775719\n",
    "\n",
    "上面那段话有点不好理解，我这里代码的实现方式还是\n",
    "\n",
    "（64，64，3，3）--split--> (64,1,3,3) -->tpu_compact_aligned，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f278a09-3f86-476e-8e64-a615cb0cdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [ 28.  29.  30.  31.  32.  33.  34.  35.  36.]\n",
      " [ 55.  56.  57.  58.  59.  60.  61.  62.  63.]\n",
      " [ 82.  83.  84.  85.  86.  87.  88.  89.  90.]\n",
      " [109. 110. 111. 112. 113. 114. 115. 116. 117.]\n",
      " [136. 137. 138. 139. 140. 141. 142. 143. 144.]\n",
      " [163. 164. 165. 166. 167. 168. 169. 170. 171.]\n",
      " [190. 191. 192. 193. 194. 195. 196. 197. 198.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 10.  11.  12.  13.  14.  15.  16.  17.  18.]\n",
      " [ 37.  38.  39.  40.  41.  42.  43.  44.  45.]\n",
      " [ 64.  65.  66.  67.  68.  69.  70.  71.  72.]\n",
      " [ 91.  92.  93.  94.  95.  96.  97.  98.  99.]\n",
      " [118. 119. 120. 121. 122. 123. 124. 125. 126.]\n",
      " [145. 146. 147. 148. 149. 150. 151. 152. 153.]\n",
      " [172. 173. 174. 175. 176. 177. 178. 179. 180.]\n",
      " [199. 200. 201. 202. 203. 204. 205. 206. 207.]]\n",
      "==================================================\n",
      "==================================================\n",
      "[[ 19.  20.  21.  22.  23.  24.  25.  26.  27.]\n",
      " [ 46.  47.  48.  49.  50.  51.  52.  53.  54.]\n",
      " [ 73.  74.  75.  76.  77.  78.  79.  80.  81.]\n",
      " [100. 101. 102. 103. 104. 105. 106. 107. 108.]\n",
      " [127. 128. 129. 130. 131. 132. 133. 134. 135.]\n",
      " [154. 155. 156. 157. 158. 159. 160. 161. 162.]\n",
      " [181. 182. 183. 184. 185. 186. 187. 188. 189.]\n",
      " [208. 209. 210. 211. 212. 213. 214. 215. 216.]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_compact_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = h*w\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "# define shape & create input\n",
    "shape = (8,3,3,3)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_compact_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,9))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da676b-d5a9-43d3-a1b9-661a383f15b2",
   "metadata": {},
   "source": [
    "### case6 64IC/32IC 存储 (INT8 64IC)\n",
    "\n",
    "* 真没有看懂\n",
    "* 感觉64IC没啥不同啊，就是紧凑型排列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecad211-f75e-4206-8ad5-6779cf7fa02d",
   "metadata": {},
   "source": [
    "### cast6 3IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d222e4-9906-4526-9a78-13977fed3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in local memory\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def split(inputs, shape, npu_num=64):\n",
    "    n,c,h,w = shape\n",
    "    if c < npu_num:\n",
    "        return [inputs[:,i:i+1] for i in range(c)], [(n,1,h,w) for i in range(c)]\n",
    "\n",
    "\n",
    "def make_tensor(arr,shape,stride):\n",
    "    arr = np.array(arr).flatten()\n",
    "    n, c, h, w = shape \n",
    "    n_stride, c_stride, h_stride, w_stride = stride\n",
    "    tn_stride = c * h * w\n",
    "    \n",
    "    tensor = np.zeros(n_stride * n)\n",
    "    for i in range(n):\n",
    "        for j in range(c):\n",
    "            for k in range(h):\n",
    "                for l in range(w):\n",
    "                    # 计算当前元素在空间中的索引\n",
    "                    tensor_index = i * n_stride + j * c_stride + k * h_stride + l * w_stride\n",
    "                    # 计算当前元素应该在输入数组中的索引\n",
    "                    arr_index = i * c * h * w + j * h * w + k * w + l\n",
    "                    # 将当前元素从输入数组放置到空间中\n",
    "                    tensor[tensor_index] = arr[arr_index]\n",
    "    return tensor\n",
    "\n",
    "def tpu_compact_stride(split_shape):\n",
    "    n, c, h, w = split_shape\n",
    "    W_stride = 1\n",
    "    H_stride = w\n",
    "    C_stride = h*w\n",
    "    N_stride = C_stride * c\n",
    "    return (N_stride, C_stride, H_stride, W_stride)\n",
    "    \n",
    "def create_input(shape):\n",
    "    n, c, h, w = shape\n",
    "    ipt = (np.arange(n*c*h*w) + 1).reshape(shape)\n",
    "    return ipt\n",
    "\n",
    "# define shape & create input\n",
    "input_shape = (8,3,3,3)\n",
    "ipt = create_input(shape)\n",
    "\n",
    "weight_shape = (64,3,5,5)\n",
    "stride_h = stride_w = 2\n",
    "\n",
    "# split for npu\n",
    "split_ipt_list, split_shape_list = split(ipt, shape)\n",
    "\n",
    "# map input to tensor in tpu memory\n",
    "for split_ipt, split_shape in zip(split_ipt_list, split_shape_list):\n",
    "    print(\"=\"*50)\n",
    "    stride = tpu_compact_stride(split_shape)\n",
    "    tensor_in_npu = make_tensor(split_ipt,split_shape,stride)\n",
    "    print(tensor_in_npu.reshape(-1,9))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9d0e1c-8e47-4bdb-b63f-ba188e168b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuyi/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18a4cb3-296e-4fa2-9ef4-4c406e0b29f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected padding to be a single integer value or a list of 2 values to match the convolution dimensions, but got padding=[0, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m depthwise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdepthwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# F.conv2d(input, weight=torch.zeros(64,3,4,4), kernel_size=4, padding=[[0,0],[0,0],[2,2],[2,2]], groups=1)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected padding to be a single integer value or a list of 2 values to match the convolution dimensions, but got padding=[0, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "depthwise = torch.nn.Conv2d(3, 64, kernel_size=3, padding=[[0,0],[0,0],[2,2],[2,2]], groups=1)\n",
    "\n",
    "input = torch.randn(4,3,224,224)\n",
    "res = F.pad(input, (0,0,2,2), 'constant', 0)\n",
    "res = depthwise(res)\n",
    "# F.conv2d(input, weight=torch.zeros(64,3,4,4), kernel_size=4, padding=[[0,0],[0,0],[2,2],[2,2]], groups=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d865380b-9762-4b06-8b28-824be50f0738",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (Tensor, group=int, padding=int, kernel_size=int, weight=Tensor), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m depthwise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (Tensor, group=int, padding=int, kernel_size=int, weight=Tensor), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n"
     ]
    }
   ],
   "source": [
    "depthwise = torch.nn.Conv2d(3, 64, kernel_size=3, padding=[[0,0],[0,0],[2,2],[2,2]], groups=3)\n",
    "\n",
    "input = torch.randn(4,3,224,224)\n",
    "F.conv2d(input, weight=torch.zeros(64,3,3,4), kernel_size=3, padding=[[0,0],[0,0],[2,2],[2,2]], group=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c655f1-53e5-4a99-9336-47edc159c07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.FloatTensor' as parameter 'bias' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdepthwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1286\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1287\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(torch.nn.Parameter or None expected)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m                         \u001b[38;5;241m.\u001b[39mformat(torch\u001b[38;5;241m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(name, value)\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' as parameter 'bias' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "depthwise.bias = torch.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8184625-2184-42cb-ae5e-a9cb5243e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthwise.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458b6407-d89c-4c15-8e1f-f318559a25ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthwise(torch.randn(1,3,16,16)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
