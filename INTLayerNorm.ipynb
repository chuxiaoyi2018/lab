{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79869fd4-9eb0-4646-92f4-569d4be39585",
   "metadata": {},
   "source": [
    "### layernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e36334-1005-4982-8736-954c6d7d1604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_969950/360994248.py\u001b[0m(31)\u001b[0;36mlayernorm\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     29 \u001b[0;31m    \u001b[0;31m# var = np.var(x, axis=-1, keepdims=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.mean(np.power(x - mean, 2), axis=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.66666667, 0.00666667, 0.00666667, 0.00666667]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.var(x, axis=-1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[0.66666667],\n",
      "        [0.00666667],\n",
      "        [0.00666667],\n",
      "        [0.00666667]]])\n"
     ]
    }
   ],
   "source": [
    "# layernorm\n",
    "# sqrt([1,197,768]) = [1,197,768]\n",
    "# int8_matrix_A = floor(255 / threshold1 * matrix_A)\n",
    "# int32_matrix_C = sqrt(int8_matrix_A)\n",
    "# float32_matrix_C = sqrt(threshold1/127) * int32_matrix_C\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def symmetrical_quantize_for_layernorm(inputs, threshold, mode=\"int8\"):\n",
    "    shape = inputs.shape\n",
    "    data = inputs\n",
    "    upper_coeff_dict = {\"int16\": 65535, \"int8\": 127, \"int4\": 15}\n",
    "    upper = upper_coeff_dict[mode]\n",
    "    lower = -128\n",
    "    \n",
    "    inv_scale = upper / threshold\n",
    "    data = np.floor(data * inv_scale + 0.5)\n",
    "    data = np.clip(data, lower, upper)\n",
    "    # for i, d in enumerate(data):\n",
    "    #     data[i] = math.floor((data[i]) * inv_scale  + 0.5)\n",
    "    #     data[i] = data[i] if data[i] < upper else upper\n",
    "    #     data[i] = data[i] if data[i] > lower else lower\n",
    "    return data.reshape(shape)\n",
    "\n",
    "def layernorm(x, alpha=1, beta=0):\n",
    "    mean = np.mean(x, axis=-1, keepdims=True)\n",
    "    var = np.power(x - mean, 2) / x.shape[-1] + 1e-7\n",
    "    # var = np.var(x, axis=-1, keepdims=True)\n",
    "    import pdb;pdb.set_trace()\n",
    "    print(var)\n",
    "    return (x - mean)/var * alpha + beta\n",
    "\n",
    "def symmetrical_dequantize_for_layernorm(inputs, threshold, mode=\"int8\"):\n",
    "    shape = inputs.shape\n",
    "    data = inputs.flatten()\n",
    "    coeff_dict = {\"int16\": 65535, \"int8\": 127, \"int4\": 15}\n",
    "    \n",
    "    scale = threshold1 / coeff_dict[mode]\n",
    "    inv_scale = 1 / scale\n",
    "    output = layernorm(inputs) * inv_scale\n",
    "    return output.reshape(shape)\n",
    "\n",
    "tensor = np.array([[[-9.0,-8.0,-7.0],[-1.9,-1.8,-1.7],[0.4,0.5,0.6],[-0.7,-0.8,-0.9]]])\n",
    "# tensor = np.random.randn(10,20,30)\n",
    "result = layernorm(tensor) # layernorm\n",
    "\n",
    "\n",
    "print(np.max(tensor))\n",
    "print(np.min(tensor))\n",
    "\n",
    "threshold1 = np.array([9, 2, 0.6, 1]).reshape(1,-1,1)\n",
    "\n",
    "int8_tensor = symmetrical_quantize_for_layernorm(tensor, threshold=threshold1)\n",
    "int8_result = symmetrical_dequantize_for_layernorm(int8_tensor, threshold=threshold1)\n",
    "\n",
    "result[:], int8_result[:]\n",
    "\n",
    "# TODO: use select from table to sqrt ( replace SqrtOp and DequantizeOp with TableOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12994e91-41ed-4f4e-9319-15f627f1bbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.99999910e+00,  0.00000000e+00,  2.99999910e+00],\n",
       "        [-2.99991000e+01,  0.00000000e+00,  2.99991000e+01],\n",
       "        [-2.99991000e+01,  0.00000000e+00,  2.99991000e+01],\n",
       "        [ 2.99991000e+01, -1.11022302e-09, -2.99991000e+01]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[-9.0,-8.0,-7.0],[-1.9,-1.8,-1.7],[0.4,0.5,0.6],[-0.7,-0.8,-0.9]]])\n",
    "tensor = np.array([[[-9.0,-8.0,-7.0],[-1.9,-1.8,-1.7],[0.4,0.5,0.6],[-0.7,-0.8,-0.9]]])\n",
    "# var = np.var(x, axis=-1, keepdims=True)\n",
    "var = np.power(x - mean, 2) / x.shape[-1] + 1e-7\n",
    "(x - mean)/var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b860a89f-b9c4-43aa-9eab-7ec44d7a5859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c4cd7d-627c-4102-bcd8-0d1b061b0405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.66666667],\n",
       "        [0.00666667],\n",
       "        [0.00666667],\n",
       "        [0.00666667]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc77efc-e969-43ad-84a6-10eb7a516ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-128 -128 -128 -128 -128 -128  123  124  124 -128 -128 -128  127  127\n",
      "  127]\n",
      "256\n",
      "[-128 -100  -72   73   76   78  127  127  127  107  104  101  127  127\n",
      "  127]\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def lowering_asymetric(data, in_scale, in_zp, upper, lower):\n",
    "    for i, d in enumerate(data):\n",
    "        data[i] = math.floor(data[i] / in_scale + in_zp)\n",
    "        data[i] = data[i] if data[i] < upper else upper\n",
    "        data[i] = data[i] if data[i] > lower else lower\n",
    "    return data\n",
    "\n",
    "def layernorm(x):\n",
    "    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
    "\n",
    "\n",
    "\n",
    "def getScaleAndZeropoint(fmax, fmin, qmax, qmin):\n",
    "    scale = (fmax - fmin) / (qmax - qmin)\n",
    "    zp = -fmin/scale + qmin\n",
    "    return scale, zp\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    inner_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)  \n",
    "    norm_b = np.linalg.norm(b)\n",
    "    cos_sim = inner_product / (norm_a * norm_b)\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def table_op(tensor, in_scale, in_zp, out_scale, out_zp, qmax, qmin):\n",
    "    int8_tensor = lowering_asymetric(tensor.flatten(), in_scale, in_zp, qmax, qmin)\n",
    "    print(int8_tensor.astype(np.int8))\n",
    "    table = []\n",
    "    for i in range(qmin,qmax+1):\n",
    "        step = (i - in_zp) * in_scale\n",
    "        table.append(np.clip(np.floor(layernorm(step) / out_scale + out_zp), -128, 127))\n",
    "    # lut\n",
    "    print(len(table))\n",
    "    lookup_value  = np.array([table[i+128] for i in int8_tensor.astype(np.int8)])\n",
    "    return (lookup_value - out_zp) * out_scale\n",
    "\n",
    "\n",
    "tensor = np.array([[-9.0,-8.0,-7.0],[-1.9,-1.8,-1.7],[49.4,49.5,49.6],[-0.7,-0.8,-0.9],[100.7,100.8,100.9]])\n",
    "\n",
    "large_posi = np.clip(tensor, 100, 10000)\n",
    "\n",
    "in_fmin = 0\n",
    "in_fmax = 50\n",
    "out_fmin = -1\n",
    "out_fmax = 50\n",
    "qmax = 127\n",
    "qmin = -128\n",
    "in_scale, in_zp = getScaleAndZeropoint(in_fmax, in_fmin, qmax, qmin)\n",
    "out_scale, out_zp = getScaleAndZeropoint(out_fmax, out_fmin, qmax, qmin)\n",
    "posi = table_op(np.clip(tensor, 0, 100), in_scale, in_zp, out_scale, out_zp, qmax, qmin)\n",
    "\n",
    "in_fmin = -9\n",
    "in_fmax = 0\n",
    "out_fmin = -1\n",
    "out_fmax = 50\n",
    "qmax = 127\n",
    "qmin = -128\n",
    "in_scale, in_zp = getScaleAndZeropoint(in_fmax, in_fmin, qmax, qmin)\n",
    "out_scale, out_zp = getScaleAndZeropoint(out_fmax, out_fmin, qmax, qmin)\n",
    "neg = table_op(np.clip(tensor, -100, 0), in_scale, in_zp, out_scale, out_zp, qmax, qmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153a6a2e-1fec-4d12-9da5-288ef1dc1a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (15,) (5,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cos_sim(\u001b[43mposi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mneg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlarge_posi\u001b[49m, np\u001b[38;5;241m.\u001b[39marray([gelu(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mflatten()]))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (15,) (5,3) "
     ]
    }
   ],
   "source": [
    "cos_sim(posi + neg + large_posi, np.array([layernorm(d) for d in tensor.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62ab46cd-beea-4a35-8141-d77c61be96dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999973385304844"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(posi + neg, np.array([layernorm(d) for d in tensor.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af7f10f-9edc-4b6a-9d65-b1a8b0ba02a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.399094149016546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22735304-3782-4f82-b75b-38f23de91d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34571400982514394"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e50aaac1-86dc-4a1a-8a2c-0edc12c28d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411919906082768"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9818e922-6db6-4960-a9f0-38f5e24228de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101 101 101 101 101 101 111 114 116 101 101 101]\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "in_fmin = -9\n",
    "in_fmax = 1\n",
    "out_fmin = -1\n",
    "out_fmax = 1\n",
    "qmax = 127\n",
    "qmin = -128\n",
    "in_scale, in_zp = getScaleAndZeropoint(in_fmax, in_fmin, qmax, qmin)\n",
    "out_scale, out_zp = getScaleAndZeropoint(out_fmax, out_fmin, qmax, qmin)\n",
    "posi = table_op(np.clip(tensor, 0, 100), in_scale, in_zp, out_scale, out_zp, qmax, qmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d27d7e39-9e72-45a7-a011-4531e8f3c9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100494021727936"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(posi, np.array([layernorm(d) for d in tensor.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dd2908d-6d63-416f-afbf-cd057246e26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0,\n",
       " -0.0,\n",
       " -2.3314683517128287e-15,\n",
       " -0.05454876554466734,\n",
       " -0.06474047315407029,\n",
       " -0.07589410444884379,\n",
       " 0.2621611694273562,\n",
       " 0.34571400982514394,\n",
       " 0.43541519923081473,\n",
       " -0.16942986529488321,\n",
       " -0.1695683085635519,\n",
       " -0.16577151129027945]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86c6d9e-e698-4c2a-8e5e-f0d5a9b616dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acfabf55-5167-48d2-88cb-eafc0b75b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd25f7b-f8e1-44b7-8f7f-010847ac9ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00784314, -0.00784314, -0.00784314, -0.09411765, -0.09411765,\n",
       "       -0.09411765,  0.20784314,  0.29411765,  0.38039216, -0.18039216,\n",
       "       -0.18039216, -0.18039216])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef086304-1545-486f-9093-5f226d561a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa0216a-2023-466f-845f-4b2da4e31887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6452a78-f1a9-4b88-a6dd-244e3e94d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(2550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cfb09e2-9d1c-4c08-8979-183e5890ba7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(1*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f892d49-c6f7-4eac-b4bd-8157cb53698e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.729535924866214"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm(1) * layernorm(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b36957a-c9ce-48a8-82ee-ce27eb74da4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0140028 , 0.0280056 , 0.0420084 ],\n",
       "       [0.0560112 , 0.070014  , 0.08401681],\n",
       "       [0.09801961, 0.11202241, 0.12602521]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int8_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8af861a-16e8-43d2-8ec2-e8d00747c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.array([[0.1,0.2,0.3],[0.4,0.5,0.6],[0.7,0.8,0.9]])\n",
    "result = 0.5 * tensor * (1 + np.tanh(np.sqrt(2/np.pi) * (tensor + 0.044715 * np.power(tensor, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20110250-c31b-4f6f-a85d-0eeae5f69454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05398275, 0.11585143, 0.18537092],\n",
       "       [0.26216117, 0.34571401, 0.4354152 ],\n",
       "       [0.53057013, 0.63043169, 0.73422849]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bbd99-8819-4965-864a-09bb91237738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "077a5159-5c4c-4729-a818-c2ebd47ec1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family 133\n",
      "not 129\n",
      "life 116\n",
      "dont 91\n",
      "no 79\n",
      "time 61\n",
      "all 53\n",
      "sad 53\n",
      "die 48\n",
      "live 46\n",
      "world 44\n",
      "there 44\n",
      "like 43\n",
      "ill 41\n",
      "can 40\n",
      "go 39\n",
      "what 39\n",
      "after 38\n",
      "parents 37\n",
      "treatment 35\n",
      "just 33\n",
      "up 33\n",
      "people 33\n",
      "death 33\n",
      "when 33\n",
      "myself 32\n",
      "leave 32\n",
      "friends 31\n",
      "also 31\n",
      "good 27\n",
      "going 27\n",
      "probably 26\n",
      "out 25\n",
      "money 25\n",
      "get 24\n",
      "give 23\n",
      "care 23\n",
      "children 23\n",
      "last 22\n",
      "really 22\n",
      "only 22\n",
      "more 22\n",
      "choose 21\n",
      "end 21\n",
      "things 21\n",
      "own 21\n",
      "lonely 21\n",
      "happy 21\n",
      "long 21\n",
      "love 21\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 去除标点符号和特殊字符\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # 将文本转换为小写\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def merge_synonyms(word_list, synonym_mapping):\n",
    "    merged_word_list = []\n",
    "    for word in word_list:\n",
    "        if word in synonym_mapping:\n",
    "            word = synonym_mapping[word]\n",
    "        merged_word_list.append(word)\n",
    "    return merged_word_list\n",
    "\n",
    "def get_top_words(word_list, n):\n",
    "    word_counts = Counter(word_list)\n",
    "    top_words = word_counts.most_common(n)\n",
    "    return top_words\n",
    "\n",
    "# 读取Word文档\n",
    "doc = Document('intimate_relationships_text.docx')\n",
    "\n",
    "# 提取文档内容\n",
    "content = ''\n",
    "for paragraph in doc.paragraphs:\n",
    "    content += paragraph.text + ' '\n",
    "\n",
    "# 预处理文本\n",
    "preprocessed_content = preprocess_text(content)\n",
    "\n",
    "# 分割文本为单词列表\n",
    "word_list = preprocessed_content.split()\n",
    "\n",
    "# 去除无用词\n",
    "stop_words = [\"i\", \"to\", 'and', 'the', 'a', 'of', 'be', 'will', 'have', 'in',\n",
    "                 'that', 'is', 'for', 'would', 'but', 'if', 'feel', 'it', 'with',\n",
    "                 'this', 'because', 'about', 'do', 'very',  'on', 'want', 'so',\n",
    "                 'them', 'think', 'they', 'as', 'their', 'or', \"i'm\", 'one', 'been',\n",
    "                 'am', 'are', 'still', 'you', 'was', 'then', 'has', 'may','my','me','im','or','at',\n",
    "              'its',]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "\n",
    "# 同义词映射关系\n",
    "synonym_mapping = {\n",
    "    \"dont want further treatment\": 'give up treatment',\n",
    "    'refuse the treatment': 'give up treatment',\n",
    "    'opt out of the treatment': 'give up treatment',\n",
    "    \"not support my treatment i will quickly give up\": 'give up treatment',\n",
    "    'forgo treatment': 'give up treatment',\n",
    "    'stop treatment': 'give up treatment',\n",
    "    'not continue with the treatment': 'give up treatment',\n",
    "    'stop them from curing me': 'give up treatment',\n",
    "    'instead of treating my illness': 'give up treatment',\n",
    "    \"cant bear the thought of my family borrowing money to pay for my treatment\": 'give up treatment',\n",
    "    \"drop the treatment\": 'give up treatment',\n",
    "    'give up treating me': 'give up treatment',\n",
    "    'no longer treating my disease': 'give up treatment',\n",
    "    'not to treat it': 'give up treatment',\n",
    "    'insist on no treatment': 'give up treatment'\n",
    "}\n",
    "\n",
    "# 合并同义词\n",
    "merged_word_list = merge_synonyms(word_list, synonym_mapping)\n",
    "\n",
    "# 获取词频前50\n",
    "top_words = get_top_words(merged_word_list, 50)\n",
    "\n",
    "# 输出结果\n",
    "for word, count in top_words:\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cdf10a2-a591-4186-a6cd-5cc59a69a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting python-docx\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /home/user/.local/lib/python3.8/site-packages (from python-docx) (4.9.3)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184600 sha256=2b718471ddbade44346ae94373fb5e3572b79bd51cac605f5ca17e050998b896\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/27/43/73/cb0f1fc89cb5f15ead03ed595453591f4db54fdd7dc8480f96\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.11\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e7c4b-071d-41e7-b1a1-a1b90eaad563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
